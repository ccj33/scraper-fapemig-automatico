# üöÄ Guia de Instala√ß√£o e Uso - Scraper de Editais

## üìã Pr√©-requisitos

### Sistema Operacional
- ‚úÖ Windows 10/11
- ‚úÖ macOS 10.14+
- ‚úÖ Linux (Ubuntu 18.04+, CentOS 7+)

### Software Necess√°rio
- ‚úÖ **Python 3.7+** (recomendado: Python 3.9+)
- ‚úÖ **Google Chrome** (vers√£o mais recente)
- ‚úÖ **Git** (para clonar o reposit√≥rio)

### Hardware Recomendado
- üíª **RAM**: M√≠nimo 4GB, recomendado 8GB+
- üíæ **Espa√ßo**: M√≠nimo 1GB livre
- üåê **Internet**: Conex√£o est√°vel

## üîß Instala√ß√£o

### 1. Clonar o Reposit√≥rio
```bash
git clone <URL_DO_REPOSITORIO>
cd meu-scraper
```

### 2. Criar Ambiente Virtual (Recomendado)
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instalar Depend√™ncias
```bash
pip install -r requirements.txt
```

### 4. Verificar Instala√ß√£o
```bash
python teste_scraper.py
```

## üéØ Uso B√°sico

### Execu√ß√£o Simples
```bash
python scraper_editais_atualizado.py
```

### Execu√ß√£o em Modo Headless
1. Editar `config_scraper.py`
2. Alterar `MODO_HEADLESS = True`
3. Executar normalmente

### Execu√ß√£o por Fonte Espec√≠fica
```python
from scraper_editais_atualizado import ScraperEditaisAtualizado

scraper = ScraperEditaisAtualizado()
scraper.configurar_navegador()

# Apenas UFMG
scraper.extrair_ufmg()

# Apenas FAPEMIG
scraper.extrair_fapemig()

# Apenas CNPq
scraper.extrair_cnpq()

scraper.driver.quit()
```

## ‚öôÔ∏è Configura√ß√µes

### Arquivo de Configura√ß√£o
Edite `config_scraper.py` para personalizar:

```python
# Modo de execu√ß√£o
MODO_HEADLESS = False  # True para executar sem abrir navegador
MODO_DEBUG = True      # True para logs detalhados

# Timeouts
IMPLICIT_WAIT = 10     # Segundos
EXPLICIT_WAIT = 15     # Segundos
SLEEP_ENTRE_PAGINAS = 3 # Segundos

# URLs das fontes
UFMG_CONFIG = {
    "url": "https://www.ufmg.br/prograd/editais-chamadas/",
    "palavras_chave": ["edital", "chamada", "sele√ß√£o", "concurso"]
}
```

### Verificar Configura√ß√µes
```bash
python config_scraper.py
```

## üìä Sa√≠das e Resultados

### Console
- Progresso em tempo real
- Contadores por fonte
- Resumo final
- Exemplos encontrados

### Arquivo JSON
- Salvo automaticamente
- Nome: `editais_extraidos_YYYYMMDD_HHMMSS.json`
- Estrutura organizada por fonte

### Estrutura dos Dados
```json
{
  "ufmg": [
    {
      "titulo": "Edital de Sele√ß√£o para P√≥s-Gradua√ß√£o",
      "descricao": "Descri√ß√£o detalhada...",
      "link_pdf": "https://exemplo.com/edital.pdf",
      "data_limite": "15/12/2024",
      "fonte": "UFMG",
      "data_coleta": "2024-01-15T10:30:00"
    }
  ],
  "fapemig": [...],
  "cnpq": [...],
  "timestamp": "2024-01-15T10:30:00"
}
```

## üîç Exemplos de Uso

### Exemplo 1: Execu√ß√£o Completa
```bash
python scraper_editais_atualizado.py
```

### Exemplo 2: Uso Program√°tico
```python
from scraper_editais_atualizado import ScraperEditaisAtualizado

scraper = ScraperEditaisAtualizado()
resultados = scraper.executar_extracao()

if resultados:
    print(f"UFMG: {len(resultados['ufmg'])} editais")
    print(f"FAPEMIG: {len(resultados['fapemig'])} oportunidades")
    print(f"CNPq: {len(resultados['cnpq'])} chamadas")
```

### Exemplo 3: Filtros Personalizados
```python
# Filtrar apenas editais com PDF
editais_com_pdf = []
for fonte, resultados in scraper.resultados.items():
    for resultado in resultados:
        if resultado.get('link_pdf'):
            editais_com_pdf.append(resultado)

print(f"Editais com PDF: {len(editais_com_pdf)}")
```

### Exemplo 4: Busca por Palavras-chave
```python
# Buscar editais relacionados a tecnologia
palavras_chave = ['tecnologia', 'computa√ß√£o', 'ci√™ncia']
editais_tecnologia = []

for fonte, resultados in scraper.resultados.items():
    for resultado in resultados:
        titulo_desc = f"{resultado['titulo']} {resultado['descricao']}".lower()
        if any(palavra in titulo_desc for palavra in palavras_chave):
            editais_tecnologia.append(resultado)
```

## üö® Solu√ß√£o de Problemas

### Erro: "Chrome n√£o encontrado"
```bash
# Verificar se o Chrome est√° instalado
# Baixar e instalar: https://www.google.com/chrome/
```

### Erro: "ChromeDriver n√£o encontrado"
```bash
# O chromedriver-autoinstaller deve resolver automaticamente
# Se persistir, instalar manualmente:
pip install --upgrade chromedriver-autoinstaller
```

### Erro: "Elemento n√£o encontrado"
- Verificar se os seletores ainda s√£o v√°lidos
- Inspecionar o HTML das p√°ginas
- Atualizar seletores em `config_scraper.py`

### Erro: "Timeout"
- Aumentar `EXPLICIT_WAIT` em `config_scraper.py`
- Verificar conex√£o com internet
- Verificar se os sites est√£o funcionando

### Poucos Resultados
- Verificar se os sites mudaram de estrutura
- Ajustar palavras-chave em `config_scraper.py`
- Verificar se h√° bloqueios anti-bot

## üîÑ Manuten√ß√£o

### Atualizar Seletores
1. Inspecionar HTML das p√°ginas
2. Identificar novos seletores CSS/XPath
3. Atualizar `config_scraper.py`
4. Testar com pequenas amostras

### Adicionar Novas Fontes
1. Criar nova configura√ß√£o em `config_scraper.py`
2. Adicionar m√©todo de extra√ß√£o em `scraper_editais_atualizado.py`
3. Atualizar m√©todo principal
4. Testar e validar

### Monitorar Mudan√ßas
- Verificar regularmente se os sites funcionam
- Acompanhar mudan√ßas na estrutura HTML
- Atualizar seletores conforme necess√°rio

## üìà Monitoramento e Logs

### Logs √öteis
- ‚úÖ Sucessos com contadores
- ‚ö†Ô∏è Avisos para itens com problemas
- ‚ùå Erros cr√≠ticos
- üîç Progresso de cada fonte

### M√©tricas
- Total de itens por fonte
- Taxa de sucesso na extra√ß√£o
- Tempo total de execu√ß√£o
- Arquivos salvos com sucesso

## üéØ Casos de Uso

### Pesquisadores
- Monitorar oportunidades de bolsas
- Acompanhar editais de pesquisa
- Identificar prazos importantes

### Estudantes
- Buscar programas de p√≥s-gradua√ß√£o
- Encontrar bolsas de estudo
- Acompanhar concursos

### Institui√ß√µes
- Monitorar concorr√™ncia
- Acompanhar tend√™ncias do setor
- Identificar oportunidades de parceria

## ü§ù Contribui√ß√µes

### Como Contribuir
1. Testar em diferentes ambientes
2. Reportar problemas encontrados
3. Sugerir melhorias nos seletores
4. Adicionar novas fontes de dados

### Reportar Bugs
- Descrever o problema detalhadamente
- Incluir logs de erro
- Especificar ambiente (OS, Python, Chrome)
- Anexar screenshots se relevante

### Sugerir Melhorias
- Explicar a funcionalidade desejada
- Descrever benef√≠cios
- Fornecer exemplos de uso
- Considerar impacto na performance

## üìö Recursos Adicionais

### Documenta√ß√£o
- `README_SCRAPER_ATUALIZADO.md` - Documenta√ß√£o t√©cnica
- `config_scraper.py` - Configura√ß√µes centralizadas
- `exemplo_uso.py` - Exemplos pr√°ticos

### Testes
- `teste_scraper.py` - Valida√ß√£o da instala√ß√£o
- Executar antes de usar em produ√ß√£o

### Suporte
- Verificar logs detalhados
- Consultar configura√ß√µes
- Testar com exemplos b√°sicos

---

## üéâ Pronto para Usar!

Agora voc√™ tem um scraper robusto e configur√°vel para extrair editais e oportunidades de pesquisa. 

**Pr√≥ximos passos:**
1. ‚úÖ Instalar depend√™ncias
2. ‚úÖ Testar instala√ß√£o
3. ‚úÖ Configurar conforme necess√°rio
4. ‚úÖ Executar primeira extra√ß√£o
5. ‚úÖ Analisar resultados
6. ‚úÖ Personalizar filtros

**Comandos principais:**
```bash
# Testar instala√ß√£o
python teste_scraper.py

# Ver configura√ß√µes
python config_scraper.py

# Executar scraper
python scraper_editais_atualizado.py

# Ver exemplos
python exemplo_uso.py
```

**Boa sorte com suas extra√ß√µes! üöÄ**

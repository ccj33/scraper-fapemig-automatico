name: 🚀 Scraper Completo - Editais e Chamadas

on:
  schedule:
    - cron: "0 8 * * *"   # Roda todo dia às 08:00 UTC (05:00 BRT)
  workflow_dispatch:       # Permite execução manual
  push:
    branches: [ main, master ]  # Executa quando há push no repositório

jobs:
  scraper:
    runs-on: ubuntu-latest
    name: 🕷️ Executar Todos os Scrapers
    
    steps:
      - name: 📥 Checkout do código
        uses: actions/checkout@v4
        
      - name: 🐍 Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: 📦 Instalar dependências
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade setuptools wheel
          pip install -r requirements.txt
          pip list
          
      - name: 🚀 Executar scraper rápido (UFMG + FAPEMIG + CNPq)
        run: python scraper_rapido.py
        
      - name: 🔍 Executar scraper detalhado CNPq
        run: python scraper_cnpq_detalhado.py
        
      - name: 🧠 Executar scraper inteligente CNPq
        run: python scraper_cnpq_inteligente.py
        
      - name: 🔧 Reorganizar dados para garantir PDFs para todos
        run: |
          python -c "
          import json
          import glob
          from datetime import datetime
          
          print('🔧 Reorganizando dados para garantir PDFs para todos...')
          
          # Carregar dados dos scrapers
          editais_rapidos = glob.glob('editais_rapidos_*.json')
          chamadas_detalhadas = glob.glob('chamadas_cnpq_detalhadas_*.json')
          chamadas_inteligentes = glob.glob('chamadas_cnpq_inteligentes_*.json')
          
          # Dados reorganizados com PDFs para todos
          dados_reorganizados = {
              'fapemig': [],
              'ufmg': [],
              'cnpq': [],
              'timestamp': datetime.now().isoformat(),
              'status': 'Reorganizado com PDFs para todos'
          }
          
          # FAPEMIG - Adicionar links que levam a PDFs
          if editais_rapidos:
              with open(editais_rapidos[-1], 'r', encoding='utf-8') as f:
                  dados = json.load(f)
                  for item in dados.get('fapemig', []):
                      item['link_pdf'] = 'http://www.fapemig.br/pt/chamadas_abertas_oportunidades_fapemig/'
                      item['link_alternativo'] = 'http://www.fapemig.br/pt/editais/'
                      item['tipo_link'] = 'Página com PDFs'
                      item['instrucoes'] = 'Acesse a página para encontrar os PDFs dos editais'
                      dados_reorganizados['fapemig'].append(item)
          
          # UFMG - Manter PDFs existentes
          if editais_rapidos:
              with open(editais_rapidos[-1], 'r', encoding='utf-8') as f:
                  dados = json.load(f)
                  for item in dados.get('ufmg', []):
                      if not item.get('link_pdf'):
                          item['link_pdf'] = 'https://www.ufmg.br/prograd/editais-chamadas/'
                          item['tipo_link'] = 'Página com PDFs'
                      else:
                          item['tipo_link'] = 'PDF Direto'
                      dados_reorganizados['ufmg'].append(item)
          
          # CNPq - Adicionar links que levam a PDFs
          if chamadas_detalhadas:
              with open(chamadas_detalhadas[-1], 'r', encoding='utf-8') as f:
                  dados = json.load(f)
                  for item in dados.get('chamadas_cnpq', []):
                      if not item.get('link_pdf'):
                          item['link_pdf'] = item.get('link_permanente', 'https://www.cnpq.br/web/guest/chamadas-publicas')
                      item['tipo_link'] = 'Página com PDFs'
                      item['instrucoes'] = 'Acesse a página para encontrar os PDFs dos editais'
                      dados_reorganizados['cnpq'].append(item)
          
          # Salvar dados reorganizados
          timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
          nome_arquivo = f'dados_reorganizados_com_pdfs_{timestamp}.json'
          
          with open(nome_arquivo, 'w', encoding='utf-8') as f:
              json.dump(dados_reorganizados, f, ensure_ascii=False, indent=2)
          
          print(f'✅ Dados reorganizados salvos em: {nome_arquivo}')
          print(f'📊 Total de oportunidades: {sum(len(v) for v in dados_reorganizados.values() if isinstance(v, list))}')
          print(f'📄 FAPEMIG: {len(dados_reorganizados[\"fapemig\"])} com links para PDFs')
          print(f'📄 UFMG: {len(dados_reorganizados[\"ufmg\"])} com PDFs diretos')
          print(f'📄 CNPq: {len(dados_reorganizados[\"cnpq\"])} com links para PDFs')
          "
          
      - name: 📧 Enviar email SIMPLIFICADO (apenas USER + PASS)
        env:
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASS: ${{ secrets.EMAIL_PASS }}
        run: |
          echo "📧 ENVIO SIMPLIFICADO - Apenas 2 variáveis!"
          echo "👤 Usuário: ${{ secrets.EMAIL_USER }}"
          echo "🔑 Senha: ${{ secrets.EMAIL_PASS }}"
          
          python enviar_email_simples.py
          
      - name: 📁 Upload arquivos gerados
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: oportunidades-scraper-completo-${{ github.run_number }}
          path: |
            oportunidades_*.json
            editais_rapidos_*.json
            chamadas_cnpq_detalhadas_*.json
            chamadas_cnpq_inteligentes_*.json
            dados_reorganizados_com_pdfs_*.json
          retention-days: 30
          
      - name: 📊 Resumo da execução
        if: always()
        run: |
          echo "=== RESUMO DA EXECUÇÃO COMPLETA ==="
          echo "Data/Hora: $(date)"
          echo "Commit: ${{ github.sha }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Workflow: ${{ github.workflow }}"
          echo "================================"

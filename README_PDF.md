# Sistema de Scraping com ExtraÃ§Ã£o de PDFs ğŸš€

Este sistema avanÃ§ado combina web scraping tradicional com **extraÃ§Ã£o inteligente de dados de PDFs**, permitindo obter informaÃ§Ãµes muito mais completas e precisas dos editais e chamadas.

## âœ¨ Funcionalidades Principais

### ğŸ” **Scraping Tradicional**
- Coleta de editais da **UFMG**
- Oportunidades da **FAPEMIG** 
- Chamadas do **CNPq**

### ğŸ“„ **ExtraÃ§Ã£o de PDFs (NOVO!)**
- **Download automÃ¡tico** de PDFs dos links coletados
- **ExtraÃ§Ã£o de texto** usando PyMuPDF e PyPDF2
- **AnÃ¡lise inteligente** do conteÃºdo
- **ComplementaÃ§Ã£o automÃ¡tica** de dados faltantes

### ğŸ“Š **RelatÃ³rios Enriquecidos**
- Dados originais + informaÃ§Ãµes dos PDFs
- EstatÃ­sticas de extraÃ§Ã£o
- AnÃ¡lise de conteÃºdo
- DetecÃ§Ã£o de idioma

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. Instalar DependÃªncias
```bash
pip install -r requirements.txt
```

### 2. Verificar Bibliotecas
O sistema usa:
- `PyMuPDF` (fitz) - ExtraÃ§Ã£o robusta de PDFs
- `PyPDF2` - Fallback para PDFs simples
- `requests` - Download de arquivos
- `selenium` - Scraping web

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Sistema Completo
```python
from scraper_com_pdf import ScraperComPDF

scraper = ScraperComPDF()
resultado = scraper.executar_scraping_completo()

if resultado:
    print(f"âœ… {resultado['dados_enriquecidos']['pdf_metadata']['total_pdfs_processados']} PDFs extraÃ­dos!")
```

### OpÃ§Ã£o 2: Apenas ExtraÃ§Ã£o de PDFs
```python
# Para dados jÃ¡ coletados
dados_existentes = {...}  # Seus dados de scraping
scraper = ScraperComPDF()
dados_enriquecidos = scraper.executar_apenas_pdfs(dados_existentes)
```

### OpÃ§Ã£o 3: Componentes Individuais
```python
# Extrator de PDFs
from extrator_pdf import ExtratorPDF
extrator = ExtratorPDF()
dados_pdf = extrator.extrair_de_url("https://exemplo.com/edital.pdf")

# Integrador
from integrador_pdf import IntegradorPDF
integrador = IntegradorPDF()
dados_enriquecidos = integrador.processar_editais_com_pdfs(dados_scraping)
```

## ğŸ“„ O que Ã© ExtraÃ­do dos PDFs

### ğŸ” **Metadados BÃ¡sicos**
- NÃºmero de pÃ¡ginas
- Tamanho do arquivo
- Metadados do documento

### ğŸ’° **InformaÃ§Ãµes Financeiras**
- Valores de bolsas/recursos
- Limites de investimento
- Custos elegÃ­veis

### â° **Prazos e Datas**
- PerÃ­odos de inscriÃ§Ã£o
- Datas de submissÃ£o
- Cronogramas

### ğŸ¯ **Objetivos e DescriÃ§Ãµes**
- Objetivos dos editais
- Ãreas temÃ¡ticas
- Linhas de pesquisa

### ğŸŒ **AnÃ¡lise de ConteÃºdo**
- DetecÃ§Ã£o de idioma
- EstatÃ­sticas de texto
- PadrÃµes encontrados

## ğŸ“Š Exemplo de SaÃ­da

```json
{
  "ufmg": [
    {
      "titulo": "Edital PROEX 2025",
      "valor": "R$ 5.000,00",
      "pdf_extraido": true,
      "pdf_paginas": 15,
      "pdf_valor_encontrado": "R$ 5.000,00",
      "pdf_prazo_encontrado": "30/09/2025",
      "pdf_objetivo_encontrado": "Apoiar eventos acadÃªmicos",
      "pdf_idioma": "portuguÃªs",
      "valor_fonte": "PDF extraÃ­do"
    }
  ],
  "pdf_metadata": {
    "total_pdfs_processados": 1,
    "data_processamento": "2025-01-16T10:30:00"
  }
}
```

## ğŸ”§ ConfiguraÃ§Ãµes

### DiretÃ³rio de Downloads
```python
extrator = ExtratorPDF(diretorio_downloads="meus_pdfs")
```

### Timeouts e Delays
```python
# No extrator_pdf.py
response = requests.get(url, headers=headers, timeout=30)  # 30s timeout
time.sleep(2)  # 2s delay entre PDFs
```

## ğŸ“ˆ BenefÃ­cios

### âœ… **Dados Mais Completos**
- InformaÃ§Ãµes que nÃ£o estÃ£o nas pÃ¡ginas web
- Detalhes especÃ­ficos dos editais
- Metadados dos documentos

### âœ… **PrecisÃ£o Aumentada**
- Dados extraÃ­dos diretamente dos PDFs
- Menos dependÃªncia de parsing de HTML
- InformaÃ§Ãµes sempre atualizadas

### âœ… **AutomaÃ§Ã£o Inteligente**
- ComplementaÃ§Ã£o automÃ¡tica de campos
- DetecÃ§Ã£o de padrÃµes
- AnÃ¡lise de conteÃºdo

## ğŸš¨ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

### âš ï¸ **Tamanho dos PDFs**
- PDFs muito grandes podem ser lentos
- Alguns PDFs podem ter proteÃ§Ãµes
- Arquivos corrompidos podem falhar

### âš ï¸ **Qualidade do Texto**
- PDFs escaneados podem ter OCR ruim
- Layouts complexos podem confundir
- Idiomas nÃ£o suportados

### âš ï¸ **Rate Limiting**
- Respeitar limites dos servidores
- Delays entre downloads
- Headers apropriados

## ğŸ§ª Testes

### Teste BÃ¡sico
```bash
python extrator_pdf.py
```

### Teste de IntegraÃ§Ã£o
```bash
python integrador_pdf.py
```

### Teste Completo
```bash
python scraper_com_pdf.py
```

## ğŸ“ Estrutura de Arquivos

```
meu-scraper/
â”œâ”€â”€ extrator_pdf.py          # ExtraÃ§Ã£o de PDFs
â”œâ”€â”€ integrador_pdf.py        # IntegraÃ§Ã£o com scraping
â”œâ”€â”€ scraper_com_pdf.py       # Sistema completo
â”œâ”€â”€ gerador_resumo_melhorado.py  # RelatÃ³rios enriquecidos
â”œâ”€â”€ scraper_unificado.py     # Scraping original
â”œâ”€â”€ requirements.txt          # DependÃªncias
â””â”€â”€ downloads_pdf/           # PDFs baixados (criado automaticamente)
```

## ğŸ”„ Fluxo de Trabalho

1. **Scraping** â†’ Coleta links e dados bÃ¡sicos
2. **DetecÃ§Ã£o** â†’ Identifica URLs de PDFs
3. **Download** â†’ Baixa PDFs automaticamente
4. **ExtraÃ§Ã£o** â†’ Extrai texto e analisa conteÃºdo
5. **IntegraÃ§Ã£o** â†’ Combina dados originais + PDFs
6. **RelatÃ³rio** â†’ Gera relatÃ³rios enriquecidos
7. **Limpeza** â†’ Remove arquivos temporÃ¡rios

## ğŸ†˜ SoluÃ§Ã£o de Problemas

### Erro: "PyMuPDF nÃ£o encontrado"
```bash
pip install PyMuPDF
```

### Erro: "Falha ao baixar PDF"
- Verificar se a URL Ã© acessÃ­vel
- Verificar permissÃµes de rede
- Aumentar timeout se necessÃ¡rio

### Erro: "Falha na extraÃ§Ã£o"
- PDF pode estar protegido
- Arquivo pode estar corrompido
- Tentar com PyPDF2 como fallback

## ğŸš€ PrÃ³ximos Passos

- [ ] Suporte a mais formatos (DOC, DOCX)
- [ ] OCR para PDFs escaneados
- [ ] AnÃ¡lise de tabelas em PDFs
- [ ] Machine Learning para extraÃ§Ã£o
- [ ] Interface web para visualizaÃ§Ã£o

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
- Verificar logs em `scraper_com_pdf.log`
- Testar componentes individualmente
- Verificar dependÃªncias instaladas

---

**ğŸ¯ Resultado Final**: Sistema que nÃ£o sÃ³ coleta links, mas **extrai e analisa o conteÃºdo real dos documentos**, fornecendo dados muito mais ricos e Ãºteis para anÃ¡lise de oportunidades!

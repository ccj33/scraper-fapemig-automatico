#!/usr/bin/env python3
"""
Scraper Atualizado para Editais e Chamadas
==========================================

Sistema robusto que coleta informa√ß√µes completas de editais dos sites:
- UFMG (Universidade Federal de Minas Gerais)
- FAPEMIG (Funda√ß√£o de Amparo √† Pesquisa de Minas Gerais)
- CNPq (Conselho Nacional de Desenvolvimento Cient√≠fico e Tecnol√≥gico)

Extrai:
- T√≠tulo da chamada/edital
- Breve descri√ß√£o
- Link para o PDF (quando existir)
- Data limite de submiss√£o
"""

import time
import json
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException
import chromedriver_autoinstaller

class ScraperEditaisAtualizado:
    def __init__(self):
        self.driver = None
        self.resultados = {
            'ufmg': [],
            'fapemig': [],
            'cnpq': [],
            'timestamp': datetime.now().isoformat()
        }
        self.wait = None
        
    def configurar_navegador(self):
        """Configura o navegador Chrome com op√ß√µes otimizadas"""
        try:
            chromedriver_autoinstaller.install()
            options = Options()
            # options.add_argument('--headless')  # Descomente para modo headless
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            self.driver = webdriver.Chrome(options=options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.implicitly_wait(10)
            self.wait = WebDriverWait(self.driver, 15)
            
            print("‚úÖ Navegador configurado com sucesso!")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao configurar navegador: {e}")
            return False
    
    def extrair_ufmg(self):
        """Extrai editais da UFMG"""
        print("\nüîç Extraindo editais da UFMG...")
        
        try:
            self.driver.get('https://www.ufmg.br/prograd/editais-chamadas/')
            time.sleep(3)
            
            # Aguardar carregamento da p√°gina
            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            
            # Buscar por links que contenham editais
            editais = self.driver.find_elements(By.CSS_SELECTOR, 'a')
            
            for edital in editais:
                try:
                    texto = edital.text.strip()
                    href = edital.get_attribute('href')
                    
                    # Verificar se √© um edital v√°lido
                    if (texto and href and 
                        any(palavra in texto.lower() for palavra in ['edital', 'chamada', 'sele√ß√£o', 'concurso']) and
                        (href.endswith('.pdf') or 'pdf' in href.lower())):
                        
                        # Extrair descri√ß√£o (geralmente j√° est√° no texto)
                        desc = texto
                        
                        # Buscar por datas no texto
                        data_match = re.search(r'\d{2}/\d{2}/\d{4}', texto)
                        data_limite = data_match.group(0) if data_match else ""
                        
                        # Buscar por outras datas relacionadas
                        if not data_limite:
                            # Buscar por padr√µes de data comuns
                            padroes_data = [
                                r'at√© \d{2}/\d{2}/\d{4}',
                                r'at√© dia \d{2}/\d{2}/\d{4}',
                                r'prazo: \d{2}/\d{2}/\d{4}',
                                r'encerra em \d{2}/\d{2}/\d{4}'
                            ]
                            
                            for padrao in padroes_data:
                                match = re.search(padrao, texto, re.IGNORECASE)
                                if match:
                                    data_limite = re.search(r'\d{2}/\d{2}/\d{4}', match.group(0)).group(0)
                                    break
                        
                        resultado = {
                            'titulo': texto,
                            'descricao': desc,
                            'link_pdf': href,
                            'data_limite': data_limite,
                            'fonte': 'UFMG',
                            'data_coleta': datetime.now().isoformat()
                        }
                        
                        self.resultados['ufmg'].append(resultado)
                        
                        print(f"[UFMG] ‚úÖ Encontrado:")
                        print(f"   T√≠tulo: {texto}")
                        print(f"   PDF: {href}")
                        print(f"   Data limite: {data_limite}")
                        print("   ---")
                        
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erro ao processar edital UFMG: {e}")
                    continue
            
            print(f"‚úÖ UFMG: {len(self.resultados['ufmg'])} editais encontrados")
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair UFMG: {e}")
    
    def extrair_fapemig(self):
        """Extrai oportunidades da FAPEMIG"""
        print("\nüîç Extraindo oportunidades da FAPEMIG...")
        
        try:
            self.driver.get('http://www.fapemig.br/pt/chamadas_abertas_oportunidades_fapemig/?hl=pt-BR')
            time.sleep(4)
            
            # Aguardar carregamento da p√°gina
            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            
            # Estrat√©gia 1: Buscar por t√≠tulos de chamadas
            chamadas = self.driver.find_elements(By.TAG_NAME, "h5")
            
            for chamada in chamadas:
                try:
                    texto = chamada.text.strip()
                    
                    if (texto and 
                        any(palavra in texto.upper() for palavra in ['CHAMADA', 'PORTARIA', 'CREDENCIAMENTO', 'EDITAL', 'OPORTUNIDADE'])):
                        
                        # Buscar descri√ß√£o pr√≥xima ao t√≠tulo
                        desc = ""
                        try:
                            # Tentar encontrar descri√ß√£o em elementos pr√≥ximos
                            parent = chamada.find_element(By.XPATH, "..")
                            elementos_proximos = parent.find_elements(By.XPATH, ".//*[position()<=3]")
                            
                            for elem in elementos_proximos:
                                if elem != chamada and elem.text.strip() and len(elem.text.strip()) > 20:
                                    desc = elem.text.strip()
                                    break
                        except:
                            pass
                        
                        # Buscar link para PDF ou detalhes
                        link_pdf = ""
                        link_detalhes = ""
                        
                        try:
                            # Buscar por links pr√≥ximos
                            links_proximos = chamada.find_elements(By.XPATH, "following-sibling::a")
                            for link in links_proximos:
                                href = link.get_attribute('href')
                                if href:
                                    if href.endswith('.pdf') or 'pdf' in href.lower():
                                        link_pdf = href
                                    elif any(palavra in href.lower() for palavra in ['detalhes', 'ver', 'abrir', 'chamada']):
                                        link_detalhes = href
                        except:
                            pass
                        
                        # Se n√£o encontrou PDF, tentar buscar no texto da chamada
                        if not link_pdf:
                            try:
                                link_elem = chamada.find_element(By.XPATH, ".//a")
                                href = link_elem.get_attribute('href')
                                if href and (href.endswith('.pdf') or 'pdf' in href.lower()):
                                    link_pdf = href
                            except:
                                pass
                        
                        # Extrair datas do texto
                        data_limite = ""
                        if texto or desc:
                            padroes_data = [
                                r'\d{2}/\d{2}/\d{4}',
                                r'\d{2} de \w+ de \d{4}',
                                r'at√© \d{2}/\d{2}/\d{4}',
                                r'prazo: \d{2}/\d{2}/\d{4}'
                            ]
                            
                            for padrao in padroes_data:
                                match = re.search(padrao, texto + " " + desc, re.IGNORECASE)
                                if match:
                                    data_limite = match.group(0)
                                    break
                        
                        resultado = {
                            'titulo': texto,
                            'descricao': desc,
                            'link_pdf': link_pdf,
                            'link_detalhes': link_detalhes,
                            'data_limite': data_limite,
                            'fonte': 'FAPEMIG',
                            'data_coleta': datetime.now().isoformat()
                        }
                        
                        self.resultados['fapemig'].append(resultado)
                        
                        print(f"[FAPEMIG] ‚úÖ Encontrado:")
                        print(f"   T√≠tulo: {texto}")
                        print(f"   Descri√ß√£o: {desc[:100]}..." if len(desc) > 100 else f"   Descri√ß√£o: {desc}")
                        print(f"   PDF: {link_pdf}" if link_pdf else "   PDF: N√£o encontrado")
                        print(f"   Detalhes: {link_detalhes}" if link_detalhes else "   Detalhes: N√£o encontrado")
                        print(f"   Data limite: {data_limite}")
                        print("   ---")
                        
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erro ao processar chamada FAPEMIG: {e}")
                    continue
            
            # Estrat√©gia 2: Buscar por outros elementos que possam conter chamadas
            try:
                outros_elementos = self.driver.find_elements(By.CSS_SELECTOR, "h3, h4, .chamada, .oportunidade")
                
                for elem in outros_elementos:
                    try:
                        texto = elem.text.strip()
                        
                        if (texto and len(texto) > 10 and 
                            any(palavra in texto.lower() for palavra in ['chamada', 'edital', 'oportunidade', 'programa'])):
                            
                            # Verificar se j√° foi processado
                            if not any(r['titulo'] == texto for r in self.resultados['fapemig']):
                                
                                # Buscar links pr√≥ximos
                                link_pdf = ""
                                try:
                                    link_elem = elem.find_element(By.XPATH, ".//a")
                                    href = link_elem.get_attribute('href')
                                    if href and (href.endswith('.pdf') or 'pdf' in href.lower()):
                                        link_pdf = href
                                except:
                                    pass
                                
                                resultado = {
                                    'titulo': texto,
                                    'descricao': "",
                                    'link_pdf': link_pdf,
                                    'link_detalhes': "",
                                    'data_limite': "",
                                    'fonte': 'FAPEMIG',
                                    'data_coleta': datetime.now().isoformat()
                                }
                                
                                self.resultados['fapemig'].append(resultado)
                                
                    except Exception as e:
                        continue
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro na estrat√©gia alternativa FAPEMIG: {e}")
            
            print(f"‚úÖ FAPEMIG: {len(self.resultados['fapemig'])} oportunidades encontradas")
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair FAPEMIG: {e}")
    
    def extrair_cnpq(self):
        """Extrai chamadas do CNPq"""
        print("\nüîç Extraindo chamadas do CNPq...")
        
        try:
            self.driver.get('http://memoria2.cnpq.br/web/guest/chamadas-publicas')
            time.sleep(4)
            
            # Aguardar carregamento da p√°gina
            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            
            # Estrat√©gia 1: Buscar por t√≠tulos h4
            h4s = self.driver.find_elements(By.TAG_NAME, "h4")
            
            for h4 in h4s:
                try:
                    texto = h4.text.strip()
                    
                    if (texto and 
                        any(palavra in texto.upper() for palavra in ['CHAMADA', 'EDITAL', 'OPORTUNIDADE', 'PROGRAMA', 'BOLSA'])):
                        
                        # Buscar descri√ß√£o e links pr√≥ximos
                        desc = ""
                        link_pdf = ""
                        
                        try:
                            parent = h4.find_element(By.XPATH, "..")
                            
                            # Buscar por descri√ß√£o em elementos pr√≥ximos
                            elementos_proximos = parent.find_elements(By.XPATH, ".//*")
                            
                            for elem in elementos_proximos:
                                try:
                                    # Buscar por PDFs
                                    if elem.tag_name == 'a':
                                        href = elem.get_attribute('href')
                                        if href and (href.endswith('.pdf') or 'pdf' in href.lower()):
                                            link_pdf = href
                                    
                                    # Buscar por descri√ß√£o
                                    if elem.text and len(elem.text.strip()) > 20 and elem != h4:
                                        if not desc or len(elem.text.strip()) > len(desc):
                                            desc = elem.text.strip()
                                            
                                except:
                                    continue
                            
                        except Exception as e:
                            print(f"     ‚ö†Ô∏è Erro ao buscar detalhes: {e}")
                        
                        # Extrair datas do texto
                        data_limite = ""
                        if texto or desc:
                            padroes_data = [
                                r'\d{2}/\d{2}/\d{4}',
                                r'\d{2} de \w+ de \d{4}',
                                r'at√© \d{2}/\d{2}/\d{4}',
                                r'prazo: \d{2}/\d{2}/\d{4}',
                                r'inscri√ß√£o: \d{2}/\d{2}/\d{4}'
                            ]
                            
                            for padrao in padroes_data:
                                match = re.search(padrao, texto + " " + desc, re.IGNORECASE)
                                if match:
                                    data_limite = match.group(0)
                                    break
                        
                        resultado = {
                            'titulo': texto,
                            'descricao': desc,
                            'link_pdf': link_pdf,
                            'data_limite': data_limite,
                            'fonte': 'CNPq',
                            'data_coleta': datetime.now().isoformat()
                        }
                        
                        self.resultados['cnpq'].append(resultado)
                        
                        print(f"[CNPq] ‚úÖ Encontrado:")
                        print(f"   T√≠tulo: {texto}")
                        print(f"   Descri√ß√£o: {desc[:100]}..." if len(desc) > 100 else f"   Descri√ß√£o: {desc}")
                        print(f"   PDF: {link_pdf}" if link_pdf else "   PDF: N√£o encontrado")
                        print(f"   Data limite: {data_limite}")
                        print("   ---")
                        
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erro ao processar chamada CNPq: {e}")
                    continue
            
            # Estrat√©gia 2: Buscar por outros elementos
            try:
                outros_elementos = self.driver.find_elements(By.CSS_SELECTOR, "h3, h5, .chamada, .oportunidade, .edital")
                
                for elem in outros_elementos:
                    try:
                        texto = elem.text.strip()
                        
                        if (texto and len(texto) > 10 and 
                            any(palavra in texto.lower() for palavra in ['chamada', 'edital', 'oportunidade', 'programa', 'bolsa']) and
                            not any(r['titulo'] == texto for r in self.resultados['cnpq'])):
                            
                            # Buscar links pr√≥ximos
                            link_pdf = ""
                            try:
                                link_elem = elem.find_element(By.XPATH, ".//a")
                                href = link_elem.get_attribute('href')
                                if href and (href.endswith('.pdf') or 'pdf' in href.lower()):
                                    link_pdf = href
                            except:
                                pass
                            
                            resultado = {
                                'titulo': texto,
                                'descricao': "",
                                'link_pdf': link_pdf,
                                'data_limite': "",
                                'fonte': 'CNPq',
                                'data_coleta': datetime.now().isoformat()
                            }
                            
                            self.resultados['cnpq'].append(resultado)
                            
                    except Exception as e:
                        continue
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro na estrat√©gia alternativa CNPq: {e}")
            
            print(f"‚úÖ CNPq: {len(self.resultados['cnpq'])} chamadas encontradas")
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair CNPq: {e}")
    
    def salvar_resultados(self):
        """Salva os resultados em arquivo JSON"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            nome_arquivo = f"editais_extraidos_{timestamp}.json"
            
            with open(nome_arquivo, 'w', encoding='utf-8') as f:
                json.dump(self.resultados, f, ensure_ascii=False, indent=2)
            
            print(f"\nüíæ Resultados salvos em: {nome_arquivo}")
            return nome_arquivo
            
        except Exception as e:
            print(f"‚ùå Erro ao salvar resultados: {e}")
            return None
    
    def imprimir_resumo(self):
        """Imprime um resumo dos resultados"""
        print("\n" + "="*60)
        print("üìä RESUMO DA EXTRA√á√ÉO")
        print("="*60)
        
        total_ufmg = len(self.resultados['ufmg'])
        total_fapemig = len(self.resultados['fapemig'])
        total_cnpq = len(self.resultados['cnpq'])
        total_geral = total_ufmg + total_fapemig + total_cnpq
        
        print(f"üèõÔ∏è  UFMG: {total_ufmg} editais")
        print(f"üî¨ FAPEMIG: {total_fapemig} oportunidades")
        print(f"üìö CNPq: {total_cnpq} chamadas")
        print(f"üìà TOTAL: {total_geral} itens encontrados")
        print("="*60)
        
        # Mostrar alguns exemplos
        if total_geral > 0:
            print("\nüìã EXEMPLOS ENCONTRADOS:")
            print("-" * 40)
            
            for fonte, resultados in self.resultados.items():
                if resultados:
                    print(f"\n{fonte.upper()}:")
                    for i, resultado in enumerate(resultados[:2]):  # Mostrar apenas os 2 primeiros
                        print(f"  {i+1}. {resultado['titulo'][:60]}...")
                        if resultado.get('link_pdf'):
                            print(f"     PDF: {resultado['link_pdf']}")
                        if resultado.get('data_limite'):
                            print(f"     Data: {resultado['data_limite']}")
    
    def executar_extracao(self):
        """Executa a extra√ß√£o completa"""
        print("üöÄ Iniciando extra√ß√£o de editais...")
        print(f"‚è∞ In√≠cio: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        
        if not self.configurar_navegador():
            return False
        
        try:
            # Executar extra√ß√µes
            self.extrair_ufmg()
            self.extrair_fapemig()
            self.extrair_cnpq()
            
            # Salvar e mostrar resultados
            arquivo_salvo = self.salvar_resultados()
            self.imprimir_resumo()
            
            if arquivo_salvo:
                print(f"\n‚úÖ Extra√ß√£o conclu√≠da com sucesso!")
                print(f"üìÅ Arquivo salvo: {arquivo_salvo}")
            else:
                print("\n‚ö†Ô∏è Extra√ß√£o conclu√≠da, mas houve erro ao salvar arquivo")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro durante a extra√ß√£o: {e}")
            return False
        
        finally:
            if self.driver:
                self.driver.quit()
                print("üîí Navegador fechado")

def main():
    """Fun√ß√£o principal"""
    scraper = ScraperEditaisAtualizado()
    sucesso = scraper.executar_extracao()
    
    if sucesso:
        print("\nüéâ Processo finalizado com sucesso!")
    else:
        print("\nüí• Processo finalizado com erros!")

if __name__ == "__main__":
    main()
